{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<div style=\"text-align: right\"><b> Ana Valentina López Chacón </b></div>\n<div style=\"text-align: right\"><b> Redes Neuronales Artificiales, 2024 - 2025 </b></div>\n\n# **Práctica MNIST: MLP Baseline**","metadata":{}},{"cell_type":"code","source":"import torch\nimport torchvision\nimport pandas as pd\nimport torch.nn as nn\nfrom tqdm import tqdm\nimport multiprocessing\nimport torch.optim as optim\nimport torch.nn.functional as  F\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader\n\nprint(\"Torch version: \", torch. __version__)\n\n####################################################################\n# Set Device\n####################################################################\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Device: \", device)","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2025-02-01T20:41:25.577041Z","iopub.execute_input":"2025-02-01T20:41:25.577349Z","iopub.status.idle":"2025-02-01T20:41:29.364463Z","shell.execute_reply.started":"2025-02-01T20:41:25.577324Z","shell.execute_reply":"2025-02-01T20:41:29.363447Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Torch version:  2.4.1+cu121\nDevice:  cuda\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"Se fijan semillas para asegurar que el experimento sea reproducible","metadata":{}},{"cell_type":"code","source":"seed = 42\ntorch.manual_seed(seed)\n\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False","metadata":{"execution":{"iopub.status.busy":"2025-02-01T20:41:29.365470Z","iopub.execute_input":"2025-02-01T20:41:29.365879Z","iopub.status.idle":"2025-02-01T20:41:29.378296Z","shell.execute_reply.started":"2025-02-01T20:41:29.365856Z","shell.execute_reply":"2025-02-01T20:41:29.377473Z"},"trusted":true},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"### **Preparación de Datos**","metadata":{}},{"cell_type":"code","source":"train_set = torchvision.datasets.MNIST('.data/', train=True, download=True)\n#train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True)\n\ntest_set = torchvision.datasets.MNIST('.data/', train=False, download=True)\n#test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=True)\n\nprint(\"Train images: \", train_set)\nprint(\"Image: \", train_set[0][0])\nprint(\"Label: \", train_set[0][1])\nprint(\"Label one hot: \", F.one_hot(torch.tensor(train_set[0][1]), num_classes=10))","metadata":{"execution":{"iopub.status.busy":"2025-02-01T20:41:29.380414Z","iopub.execute_input":"2025-02-01T20:41:29.380663Z","iopub.status.idle":"2025-02-01T20:41:33.117439Z","shell.execute_reply.started":"2025-02-01T20:41:29.380642Z","shell.execute_reply":"2025-02-01T20:41:33.116622Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\nFailed to download (trying next):\n<urlopen error [Errno 111] Connection refused>\n\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to .data/MNIST/raw/train-images-idx3-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 9912422/9912422 [00:00<00:00, 17150854.08it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting .data/MNIST/raw/train-images-idx3-ubyte.gz to .data/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\nFailed to download (trying next):\n<urlopen error [Errno 111] Connection refused>\n\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to .data/MNIST/raw/train-labels-idx1-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 28881/28881 [00:00<00:00, 456528.37it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting .data/MNIST/raw/train-labels-idx1-ubyte.gz to .data/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\nFailed to download (trying next):\n<urlopen error [Errno 111] Connection refused>\n\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to .data/MNIST/raw/t10k-images-idx3-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1648877/1648877 [00:00<00:00, 4238501.84it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting .data/MNIST/raw/t10k-images-idx3-ubyte.gz to .data/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\nFailed to download (trying next):\n<urlopen error [Errno 111] Connection refused>\n\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to .data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 4542/4542 [00:00<00:00, 8311749.03it/s]","output_type":"stream"},{"name":"stdout","text":"Extracting .data/MNIST/raw/t10k-labels-idx1-ubyte.gz to .data/MNIST/raw\n\nTrain images:  Dataset MNIST\n    Number of datapoints: 60000\n    Root location: .data/\n    Split: Train\nImage:  <PIL.Image.Image image mode=L size=28x28 at 0x78FBD7766B30>\nLabel:  5\nLabel one hot:  tensor([0, 0, 0, 0, 0, 1, 0, 0, 0, 0])\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"### **Clase dataset**","metadata":{}},{"cell_type":"code","source":"class MNIST_dataset(Dataset):\n\n    def __init__(self, data, partition = \"train\"):\n\n        print(\"\\nLoading MNIST \", partition, \" Dataset...\")\n        self.data = data\n        self.partition = partition\n        print(\"\\tTotal Len.: \", len(self.data), \"\\n\", 50*\"-\")\n\n    def __len__(self):\n        return len(self.data)\n    \n    def from_pil_to_tensor(self, image):\n        return torchvision.transforms.ToTensor()(image)\n\n    def __getitem__(self, idx):\n\n        # Image\n        image = self.data[idx][0]\n        # PIL Image to torch tensor\n        image_tensor = self.from_pil_to_tensor(image)\n        # care! net expect a 784 size vector and our dataset \n        # provide 1x28x28 (channels, height, width) -> Reshape!\n        image_tensor = image_tensor.view(-1)\n\n        # Label\n        label = torch.tensor(self.data[idx][1])\n        label = F.one_hot(label, num_classes=10).float()\n\n        return {\"img\": image_tensor, \"label\": label}\n\ntrain_dataset = MNIST_dataset(train_set, partition=\"train\")\ntest_dataset = MNIST_dataset(test_set, partition=\"test\")","metadata":{"execution":{"iopub.status.busy":"2025-02-01T20:41:33.118558Z","iopub.execute_input":"2025-02-01T20:41:33.118812Z","iopub.status.idle":"2025-02-01T20:41:33.127846Z","shell.execute_reply.started":"2025-02-01T20:41:33.118791Z","shell.execute_reply":"2025-02-01T20:41:33.127050Z"},"trusted":true},"outputs":[{"name":"stdout","text":"\nLoading MNIST  train  Dataset...\n\tTotal Len.:  60000 \n --------------------------------------------------\n\nLoading MNIST  test  Dataset...\n\tTotal Len.:  10000 \n --------------------------------------------------\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"batch_size = 100\nnum_workers = multiprocessing.cpu_count()-1\nprint(\"Num workers\", num_workers)\ntrain_dataloader = DataLoader(train_dataset, batch_size, shuffle=True, num_workers=num_workers)\ntest_dataloader = DataLoader(test_dataset, batch_size, shuffle=False, num_workers=num_workers)","metadata":{"execution":{"iopub.status.busy":"2025-02-01T20:41:33.128608Z","iopub.execute_input":"2025-02-01T20:41:33.128794Z","iopub.status.idle":"2025-02-01T20:41:33.152230Z","shell.execute_reply.started":"2025-02-01T20:41:33.128777Z","shell.execute_reply":"2025-02-01T20:41:33.151419Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Num workers 3\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"### **Clase Red**","metadata":{}},{"cell_type":"code","source":"class Net(nn.Module):\n    def __init__(self, num_classes):\n        super(Net, self).__init__()\n        self.linear1 = nn.Linear(784, 1024)\n        self.relu1 = nn.ReLU()\n        self.linear2 = nn.Linear(1024, 1024)\n        self.relu2 = nn.ReLU()\n        self.linear3 = nn.Linear(1024, 1024)\n        self.relu3 = nn.ReLU()\n        self.classifier = nn.Linear(1024, num_classes)\n\n    def forward(self, x):\n        out = self.relu1(self.linear1(x))\n        out = self.relu2(self.linear2(out))\n        out = self.relu3(self.linear3(out))\n        out = self.classifier(out)\n        return out\n\n\n# Instantiating the network and printing its architecture\nnum_classes = 10\nnet = Net(num_classes)\nprint(net)\n\ndef count_parameters(model):\n    return sum(p.numel() for p in model.parameters() if p.requires_grad)\nprint(\"Params: \", count_parameters(net))","metadata":{"execution":{"iopub.status.busy":"2025-02-01T20:41:33.153098Z","iopub.execute_input":"2025-02-01T20:41:33.153373Z","iopub.status.idle":"2025-02-01T20:41:33.192213Z","shell.execute_reply.started":"2025-02-01T20:41:33.153346Z","shell.execute_reply":"2025-02-01T20:41:33.191609Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Net(\n  (linear1): Linear(in_features=784, out_features=1024, bias=True)\n  (relu1): ReLU()\n  (linear2): Linear(in_features=1024, out_features=1024, bias=True)\n  (relu2): ReLU()\n  (linear3): Linear(in_features=1024, out_features=1024, bias=True)\n  (relu3): ReLU()\n  (classifier): Linear(in_features=1024, out_features=10, bias=True)\n)\nParams:  2913290\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# Training hyperparameters\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(net.parameters(), lr=0.01, weight_decay=1e-6, momentum=0.9)\nepochs = 45","metadata":{"execution":{"iopub.status.busy":"2025-02-01T20:41:33.192896Z","iopub.execute_input":"2025-02-01T20:41:33.193121Z","iopub.status.idle":"2025-02-01T20:41:33.197014Z","shell.execute_reply.started":"2025-02-01T20:41:33.193102Z","shell.execute_reply":"2025-02-01T20:41:33.196128Z"},"trusted":true},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"### **Entrenamiento**","metadata":{}},{"cell_type":"code","source":"# Load model in GPU\nnet.to(device)\n\nprint(\"\\n---- Start Training ----\")\nbest_accuracy = -1\nbest_epoch = 0\nfor epoch in range(epochs):\n\n\n    # TRAIN NETWORK\n    train_loss, train_correct = 0, 0\n    net.train()\n    with tqdm(iter(train_dataloader), desc=\"Epoch \" + str(epoch), unit=\"batch\") as tepoch:\n        for batch in tepoch:\n            \n            # Returned values of Dataset Class\n            images = batch[\"img\"].to(device)\n            labels = batch[\"label\"].to(device)\n\n            # zero the parameter gradients\n            optimizer.zero_grad()\n\n            # Forward\n            outputs = net(images)\n            loss = criterion(outputs, labels)\n\n            # Calculate gradients\n            loss.backward()\n\n            # Update gradients\n            optimizer.step()\n\n            # one hot -> labels\n            labels = torch.argmax(labels, dim=1)\n            pred = torch.argmax(outputs, dim=1)\n            train_correct += pred.eq(labels).sum().item()\n\n            # print statistics\n            train_loss += loss.item()\n\n    train_loss /= len(train_dataloader.dataset)\n\n    # TEST NETWORK\n    test_loss, test_correct = 0, 0\n    net.eval()\n    with torch.no_grad():\n      with tqdm(iter(test_dataloader), desc=\"Test \" + str(epoch), unit=\"batch\") as tepoch:\n          for batch in tepoch:\n\n            images = batch[\"img\"].to(device)\n            labels = batch[\"label\"].to(device)\n\n            # Forward\n            outputs = net(images)\n            test_loss += criterion(outputs, labels)\n\n            # one hot -> labels\n            labels = torch.argmax(labels, dim=1)\n            pred = torch.argmax(outputs, dim=1)\n\n            test_correct += pred.eq(labels).sum().item()\n\n    test_loss /= len(test_dataloader.dataset)\n    test_accuracy = 100. * test_correct / len(test_dataloader.dataset)\n\n    print(\"[Epoch {}] Train Loss: {:.6f} - Test Loss: {:.6f} - Train Accuracy: {:.2f}% - Test Accuracy: {:.2f}%\".format(\n        epoch + 1, train_loss, test_loss, 100. * train_correct / len(train_dataloader.dataset), test_accuracy\n    ))\n\n    if test_accuracy > best_accuracy:\n        best_accuracy = test_accuracy\n        best_epoch = epoch\n\n        # Save best weights\n        torch.save(net.state_dict(), \"best_model_mnist_mlp.pt\")\n\nprint(\"\\nBEST TEST ACCURACY: \", best_accuracy, \" in epoch \", best_epoch)","metadata":{"execution":{"iopub.status.busy":"2025-02-01T20:41:33.198582Z","iopub.execute_input":"2025-02-01T20:41:33.198829Z","iopub.status.idle":"2025-02-01T20:47:00.016996Z","shell.execute_reply.started":"2025-02-01T20:41:33.198810Z","shell.execute_reply":"2025-02-01T20:47:00.016147Z"},"trusted":true},"outputs":[{"name":"stdout","text":"\n---- Start Training ----\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0: 100%|██████████| 600/600 [00:06<00:00, 91.88batch/s] \nTest 0: 100%|██████████| 100/100 [00:01<00:00, 98.01batch/s]","output_type":"stream"},{"name":"stdout","text":"[Epoch 1] Train Loss: 0.007253 - Test Loss: 0.002581 - Train Accuracy: 79.84% - Test Accuracy: 92.24%\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 1: 100%|██████████| 600/600 [00:06<00:00, 96.57batch/s] \nTest 1: 100%|██████████| 100/100 [00:01<00:00, 97.43batch/s]","output_type":"stream"},{"name":"stdout","text":"[Epoch 2] Train Loss: 0.002061 - Test Loss: 0.001518 - Train Accuracy: 93.90% - Test Accuracy: 95.56%\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 2: 100%|██████████| 600/600 [00:05<00:00, 100.81batch/s]\nTest 2: 100%|██████████| 100/100 [00:01<00:00, 97.19batch/s]","output_type":"stream"},{"name":"stdout","text":"[Epoch 3] Train Loss: 0.001300 - Test Loss: 0.001154 - Train Accuracy: 96.18% - Test Accuracy: 96.44%\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 3: 100%|██████████| 600/600 [00:06<00:00, 98.78batch/s] \nTest 3: 100%|██████████| 100/100 [00:01<00:00, 98.61batch/s]","output_type":"stream"},{"name":"stdout","text":"[Epoch 4] Train Loss: 0.000956 - Test Loss: 0.000971 - Train Accuracy: 97.18% - Test Accuracy: 97.17%\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 4: 100%|██████████| 600/600 [00:05<00:00, 100.28batch/s]\nTest 4: 100%|██████████| 100/100 [00:01<00:00, 98.59batch/s]","output_type":"stream"},{"name":"stdout","text":"[Epoch 5] Train Loss: 0.000714 - Test Loss: 0.000826 - Train Accuracy: 97.87% - Test Accuracy: 97.43%\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 5: 100%|██████████| 600/600 [00:05<00:00, 100.63batch/s]\nTest 5: 100%|██████████| 100/100 [00:01<00:00, 90.07batch/s]","output_type":"stream"},{"name":"stdout","text":"[Epoch 6] Train Loss: 0.000558 - Test Loss: 0.000805 - Train Accuracy: 98.33% - Test Accuracy: 97.46%\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 6: 100%|██████████| 600/600 [00:06<00:00, 98.03batch/s] \nTest 6: 100%|██████████| 100/100 [00:01<00:00, 98.12batch/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 7] Train Loss: 0.000436 - Test Loss: 0.000678 - Train Accuracy: 98.75% - Test Accuracy: 97.95%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7: 100%|██████████| 600/600 [00:06<00:00, 98.45batch/s] \nTest 7: 100%|██████████| 100/100 [00:01<00:00, 98.74batch/s]","output_type":"stream"},{"name":"stdout","text":"[Epoch 8] Train Loss: 0.000348 - Test Loss: 0.000679 - Train Accuracy: 98.97% - Test Accuracy: 97.86%\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 8: 100%|██████████| 600/600 [00:05<00:00, 100.51batch/s]\nTest 8: 100%|██████████| 100/100 [00:01<00:00, 90.64batch/s]","output_type":"stream"},{"name":"stdout","text":"[Epoch 9] Train Loss: 0.000286 - Test Loss: 0.000835 - Train Accuracy: 99.19% - Test Accuracy: 97.59%\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 9: 100%|██████████| 600/600 [00:05<00:00, 100.43batch/s]\nTest 9: 100%|██████████| 100/100 [00:01<00:00, 95.41batch/s] ","output_type":"stream"},{"name":"stdout","text":"[Epoch 10] Train Loss: 0.000212 - Test Loss: 0.000639 - Train Accuracy: 99.42% - Test Accuracy: 98.02%\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 10: 100%|██████████| 600/600 [00:06<00:00, 94.79batch/s] \nTest 10: 100%|██████████| 100/100 [00:01<00:00, 97.22batch/s]","output_type":"stream"},{"name":"stdout","text":"[Epoch 11] Train Loss: 0.000173 - Test Loss: 0.000636 - Train Accuracy: 99.53% - Test Accuracy: 98.17%\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 11: 100%|██████████| 600/600 [00:06<00:00, 98.69batch/s] \nTest 11: 100%|██████████| 100/100 [00:01<00:00, 97.36batch/s]","output_type":"stream"},{"name":"stdout","text":"[Epoch 12] Train Loss: 0.000124 - Test Loss: 0.000634 - Train Accuracy: 99.70% - Test Accuracy: 98.14%\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 12: 100%|██████████| 600/600 [00:05<00:00, 100.66batch/s]\nTest 12: 100%|██████████| 100/100 [00:01<00:00, 97.19batch/s]","output_type":"stream"},{"name":"stdout","text":"[Epoch 13] Train Loss: 0.000091 - Test Loss: 0.000658 - Train Accuracy: 99.80% - Test Accuracy: 98.23%\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 13: 100%|██████████| 600/600 [00:06<00:00, 98.92batch/s] \nTest 13: 100%|██████████| 100/100 [00:00<00:00, 100.87batch/s]","output_type":"stream"},{"name":"stdout","text":"[Epoch 14] Train Loss: 0.000060 - Test Loss: 0.000678 - Train Accuracy: 99.91% - Test Accuracy: 98.13%\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 14: 100%|██████████| 600/600 [00:06<00:00, 96.50batch/s] \nTest 14: 100%|██████████| 100/100 [00:01<00:00, 93.33batch/s]","output_type":"stream"},{"name":"stdout","text":"[Epoch 15] Train Loss: 0.000045 - Test Loss: 0.000651 - Train Accuracy: 99.94% - Test Accuracy: 98.18%\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 15: 100%|██████████| 600/600 [00:06<00:00, 99.93batch/s] \nTest 15: 100%|██████████| 100/100 [00:01<00:00, 92.47batch/s]","output_type":"stream"},{"name":"stdout","text":"[Epoch 16] Train Loss: 0.000032 - Test Loss: 0.000636 - Train Accuracy: 99.97% - Test Accuracy: 98.28%\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 16: 100%|██████████| 600/600 [00:06<00:00, 99.14batch/s] \nTest 16: 100%|██████████| 100/100 [00:01<00:00, 97.20batch/s]","output_type":"stream"},{"name":"stdout","text":"[Epoch 17] Train Loss: 0.000024 - Test Loss: 0.000645 - Train Accuracy: 99.98% - Test Accuracy: 98.24%\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 17: 100%|██████████| 600/600 [00:06<00:00, 98.80batch/s] \nTest 17: 100%|██████████| 100/100 [00:00<00:00, 100.18batch/s]","output_type":"stream"},{"name":"stdout","text":"[Epoch 18] Train Loss: 0.000018 - Test Loss: 0.000686 - Train Accuracy: 100.00% - Test Accuracy: 98.28%\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 18: 100%|██████████| 600/600 [00:06<00:00, 98.94batch/s] \nTest 18: 100%|██████████| 100/100 [00:01<00:00, 93.68batch/s]","output_type":"stream"},{"name":"stdout","text":"[Epoch 19] Train Loss: 0.000014 - Test Loss: 0.000663 - Train Accuracy: 100.00% - Test Accuracy: 98.39%\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 19: 100%|██████████| 600/600 [00:06<00:00, 95.62batch/s] \nTest 19: 100%|██████████| 100/100 [00:01<00:00, 93.62batch/s]","output_type":"stream"},{"name":"stdout","text":"[Epoch 20] Train Loss: 0.000012 - Test Loss: 0.000682 - Train Accuracy: 100.00% - Test Accuracy: 98.29%\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 20: 100%|██████████| 600/600 [00:05<00:00, 100.04batch/s]\nTest 20: 100%|██████████| 100/100 [00:01<00:00, 99.17batch/s]","output_type":"stream"},{"name":"stdout","text":"[Epoch 21] Train Loss: 0.000010 - Test Loss: 0.000687 - Train Accuracy: 100.00% - Test Accuracy: 98.37%\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 21: 100%|██████████| 600/600 [00:06<00:00, 99.61batch/s] \nTest 21: 100%|██████████| 100/100 [00:01<00:00, 96.67batch/s]","output_type":"stream"},{"name":"stdout","text":"[Epoch 22] Train Loss: 0.000009 - Test Loss: 0.000686 - Train Accuracy: 100.00% - Test Accuracy: 98.39%\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 22: 100%|██████████| 600/600 [00:05<00:00, 100.20batch/s]\nTest 22: 100%|██████████| 100/100 [00:01<00:00, 96.34batch/s] ","output_type":"stream"},{"name":"stdout","text":"[Epoch 23] Train Loss: 0.000008 - Test Loss: 0.000698 - Train Accuracy: 100.00% - Test Accuracy: 98.33%\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 23: 100%|██████████| 600/600 [00:06<00:00, 95.53batch/s] \nTest 23: 100%|██████████| 100/100 [00:01<00:00, 94.09batch/s]","output_type":"stream"},{"name":"stdout","text":"[Epoch 24] Train Loss: 0.000007 - Test Loss: 0.000691 - Train Accuracy: 100.00% - Test Accuracy: 98.38%\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 24: 100%|██████████| 600/600 [00:06<00:00, 98.67batch/s] \nTest 24: 100%|██████████| 100/100 [00:01<00:00, 98.07batch/s]","output_type":"stream"},{"name":"stdout","text":"[Epoch 25] Train Loss: 0.000006 - Test Loss: 0.000701 - Train Accuracy: 100.00% - Test Accuracy: 98.34%\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 25: 100%|██████████| 600/600 [00:06<00:00, 99.26batch/s] \nTest 25: 100%|██████████| 100/100 [00:01<00:00, 99.84batch/s]","output_type":"stream"},{"name":"stdout","text":"[Epoch 26] Train Loss: 0.000006 - Test Loss: 0.000708 - Train Accuracy: 100.00% - Test Accuracy: 98.37%\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 26: 100%|██████████| 600/600 [00:05<00:00, 100.14batch/s]\nTest 26: 100%|██████████| 100/100 [00:01<00:00, 92.98batch/s]","output_type":"stream"},{"name":"stdout","text":"[Epoch 27] Train Loss: 0.000005 - Test Loss: 0.000708 - Train Accuracy: 100.00% - Test Accuracy: 98.36%\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 27: 100%|██████████| 600/600 [00:06<00:00, 99.35batch/s] \nTest 27: 100%|██████████| 100/100 [00:01<00:00, 91.28batch/s]","output_type":"stream"},{"name":"stdout","text":"[Epoch 28] Train Loss: 0.000005 - Test Loss: 0.000719 - Train Accuracy: 100.00% - Test Accuracy: 98.36%\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 28: 100%|██████████| 600/600 [00:06<00:00, 96.44batch/s] \nTest 28: 100%|██████████| 100/100 [00:01<00:00, 98.42batch/s]","output_type":"stream"},{"name":"stdout","text":"[Epoch 29] Train Loss: 0.000005 - Test Loss: 0.000720 - Train Accuracy: 100.00% - Test Accuracy: 98.35%\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 29: 100%|██████████| 600/600 [00:06<00:00, 98.12batch/s] \nTest 29: 100%|██████████| 100/100 [00:01<00:00, 98.03batch/s]","output_type":"stream"},{"name":"stdout","text":"[Epoch 30] Train Loss: 0.000004 - Test Loss: 0.000729 - Train Accuracy: 100.00% - Test Accuracy: 98.34%\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 30: 100%|██████████| 600/600 [00:06<00:00, 99.86batch/s] \nTest 30: 100%|██████████| 100/100 [00:01<00:00, 98.66batch/s]","output_type":"stream"},{"name":"stdout","text":"[Epoch 31] Train Loss: 0.000004 - Test Loss: 0.000727 - Train Accuracy: 100.00% - Test Accuracy: 98.34%\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 31: 100%|██████████| 600/600 [00:06<00:00, 98.54batch/s] \nTest 31: 100%|██████████| 100/100 [00:00<00:00, 100.49batch/s]","output_type":"stream"},{"name":"stdout","text":"[Epoch 32] Train Loss: 0.000004 - Test Loss: 0.000729 - Train Accuracy: 100.00% - Test Accuracy: 98.39%\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 32: 100%|██████████| 600/600 [00:06<00:00, 94.12batch/s] \nTest 32: 100%|██████████| 100/100 [00:01<00:00, 99.83batch/s]","output_type":"stream"},{"name":"stdout","text":"[Epoch 33] Train Loss: 0.000004 - Test Loss: 0.000734 - Train Accuracy: 100.00% - Test Accuracy: 98.37%\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 33: 100%|██████████| 600/600 [00:06<00:00, 99.05batch/s] \nTest 33: 100%|██████████| 100/100 [00:01<00:00, 96.89batch/s]","output_type":"stream"},{"name":"stdout","text":"[Epoch 34] Train Loss: 0.000003 - Test Loss: 0.000738 - Train Accuracy: 100.00% - Test Accuracy: 98.31%\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 34: 100%|██████████| 600/600 [00:05<00:00, 100.35batch/s]\nTest 34: 100%|██████████| 100/100 [00:01<00:00, 98.57batch/s]","output_type":"stream"},{"name":"stdout","text":"[Epoch 35] Train Loss: 0.000003 - Test Loss: 0.000748 - Train Accuracy: 100.00% - Test Accuracy: 98.34%\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 35: 100%|██████████| 600/600 [00:06<00:00, 96.53batch/s] \nTest 35: 100%|██████████| 100/100 [00:01<00:00, 98.15batch/s]","output_type":"stream"},{"name":"stdout","text":"[Epoch 36] Train Loss: 0.000003 - Test Loss: 0.000747 - Train Accuracy: 100.00% - Test Accuracy: 98.34%\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 36: 100%|██████████| 600/600 [00:06<00:00, 96.50batch/s] \nTest 36: 100%|██████████| 100/100 [00:01<00:00, 90.72batch/s]","output_type":"stream"},{"name":"stdout","text":"[Epoch 37] Train Loss: 0.000003 - Test Loss: 0.000748 - Train Accuracy: 100.00% - Test Accuracy: 98.38%\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 37: 100%|██████████| 600/600 [00:06<00:00, 99.79batch/s] \nTest 37: 100%|██████████| 100/100 [00:01<00:00, 93.66batch/s]","output_type":"stream"},{"name":"stdout","text":"[Epoch 38] Train Loss: 0.000003 - Test Loss: 0.000755 - Train Accuracy: 100.00% - Test Accuracy: 98.35%\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 38: 100%|██████████| 600/600 [00:06<00:00, 99.86batch/s] \nTest 38: 100%|██████████| 100/100 [00:01<00:00, 97.63batch/s]","output_type":"stream"},{"name":"stdout","text":"[Epoch 39] Train Loss: 0.000003 - Test Loss: 0.000758 - Train Accuracy: 100.00% - Test Accuracy: 98.38%\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 39: 100%|██████████| 600/600 [00:06<00:00, 97.72batch/s] \nTest 39: 100%|██████████| 100/100 [00:01<00:00, 97.50batch/s]","output_type":"stream"},{"name":"stdout","text":"[Epoch 40] Train Loss: 0.000003 - Test Loss: 0.000760 - Train Accuracy: 100.00% - Test Accuracy: 98.33%\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 40: 100%|██████████| 600/600 [00:06<00:00, 97.92batch/s] \nTest 40: 100%|██████████| 100/100 [00:01<00:00, 94.86batch/s]","output_type":"stream"},{"name":"stdout","text":"[Epoch 41] Train Loss: 0.000003 - Test Loss: 0.000760 - Train Accuracy: 100.00% - Test Accuracy: 98.33%\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 41: 100%|██████████| 600/600 [00:06<00:00, 94.38batch/s] \nTest 41: 100%|██████████| 100/100 [00:01<00:00, 98.57batch/s]","output_type":"stream"},{"name":"stdout","text":"[Epoch 42] Train Loss: 0.000002 - Test Loss: 0.000762 - Train Accuracy: 100.00% - Test Accuracy: 98.36%\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 42: 100%|██████████| 600/600 [00:06<00:00, 98.94batch/s] \nTest 42: 100%|██████████| 100/100 [00:01<00:00, 98.94batch/s]","output_type":"stream"},{"name":"stdout","text":"[Epoch 43] Train Loss: 0.000002 - Test Loss: 0.000766 - Train Accuracy: 100.00% - Test Accuracy: 98.31%\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 43: 100%|██████████| 600/600 [00:06<00:00, 98.77batch/s] \nTest 43: 100%|██████████| 100/100 [00:00<00:00, 100.03batch/s]","output_type":"stream"},{"name":"stdout","text":"[Epoch 44] Train Loss: 0.000002 - Test Loss: 0.000769 - Train Accuracy: 100.00% - Test Accuracy: 98.36%\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 44: 100%|██████████| 600/600 [00:06<00:00, 98.63batch/s] \nTest 44: 100%|██████████| 100/100 [00:01<00:00, 95.64batch/s]","output_type":"stream"},{"name":"stdout","text":"[Epoch 45] Train Loss: 0.000002 - Test Loss: 0.000771 - Train Accuracy: 100.00% - Test Accuracy: 98.34%\n\nBEST TEST ACCURACY:  98.39  in epoch  18\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# Load best weights\nnet.load_state_dict(torch.load(\"best_model_mnist_mlp.pt\"))\n\ntest_loss, test_correct = 0, 0\nnet.eval()\nwith torch.no_grad():\n    with tqdm(iter(test_dataloader), desc=\"Test \" + str(epoch), unit=\"batch\") as tepoch:\n        for batch in tepoch:\n\n            images = batch[\"img\"].to(device)\n            labels = batch[\"label\"].to(device)\n\n            # Forward\n            outputs = net(images)\n            test_loss += criterion(outputs, labels)\n\n            # one hot -> labels\n            labels = torch.argmax(labels, dim=1)\n            pred = torch.argmax(outputs, dim=1)\n\n            test_correct += pred.eq(labels).sum().item()\n\n    test_loss /= len(test_dataloader.dataset)\n    test_accuracy = 100. * test_correct / len(test_dataloader.dataset)\nprint(\"Final best acc: \", test_accuracy)","metadata":{"execution":{"iopub.status.busy":"2025-02-01T20:47:00.018199Z","iopub.execute_input":"2025-02-01T20:47:00.018468Z","iopub.status.idle":"2025-02-01T20:47:01.108012Z","shell.execute_reply.started":"2025-02-01T20:47:00.018443Z","shell.execute_reply":"2025-02-01T20:47:01.107088Z"},"trusted":true},"outputs":[{"name":"stderr","text":"<ipython-input-9-c983ce0656a1>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  net.load_state_dict(torch.load(\"best_model_mnist_mlp.pt\"))\nTest 44: 100%|██████████| 100/100 [00:01<00:00, 98.06batch/s]","output_type":"stream"},{"name":"stdout","text":"Final best acc:  98.39\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":9}]}